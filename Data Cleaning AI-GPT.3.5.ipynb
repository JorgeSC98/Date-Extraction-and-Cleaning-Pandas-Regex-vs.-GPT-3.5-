{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda23084",
   "metadata": {},
   "source": [
    "# Data Cleaning with gpt-3.5-turbo of openai\n",
    "In this Notebook, we will make use of Chatgpt gpt-3.5-turbo api to apply data cleaning.\n",
    "Each line of the dates.txt file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset, and compare performance results of this artifical intelligence tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b0bf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490                                  Lab: B12 969 2007\\n\n",
       "491                                   )and 8mo in 2009\\n\n",
       "492    .Moved to USA in 1986. Suffered from malnutrit...\n",
       "493                                              r1978\\n\n",
       "494    . Went to Emerson, in Newfane Alaska. Started ...\n",
       "495    1979 Family Psych History: Family History of S...\n",
       "496    therapist and friend died in ~2006 Parental/Ca...\n",
       "497                         2008 partial thyroidectomy\\n\n",
       "498    sPt describes a history of sexual abuse as a c...\n",
       "499    . In 1980, patient was living in Naples and de...\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, let's import some libraries, open our dataset and print some examples.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import regex as re\n",
    "import random\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "list_=[]\n",
    "list_=list(df.values)\n",
    "len(list_)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13573c",
   "metadata": {},
   "source": [
    "Now, let's import openai and define our api_key, this key can be found in your account settings in openai.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acad28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key  ='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d9c6b",
   "metadata": {},
   "source": [
    "*get_completion function uses gpt-3.5-turbo to get a response of the model sending only the prompt with the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552c5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc950c",
   "metadata": {},
   "source": [
    "Now, let's create a foor loop to iterate over the sentences in the dataset, each sentence in the list will be used as the \n",
    "text for gpt to extract the dates. \n",
    "The prompt is a simple paragraph of 4 lines, where we inidcate where the text is, what to do whith this text, and how do\n",
    "we need the results.\n",
    "For this example we will pass in batches of 50 sentences, and we will only use half of the dataset, so we will call gpt just\n",
    "five times. \n",
    "The purpose of this calls are to extract the date of each sentence, we will end up with a appended list with all the dates\n",
    "extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fb659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03/25/93', '6/18/85', '7/8/71', '9/27/75', '2/6/96', '7/06/79', '5/18/78', '10/24/89', '3/7/86', '4/10/71', '5/11/85', '4/09/75', '8/01/98', '1/26/72', '5/24/1990', '1/25/2011', '4/12/82', '10/13/1976', '4/24/98', '5/21/77', '7/21/98', '10/21/... '9/22/89', '9/02/76', '9/12/71', '10/24/86', '03/31/1985', '7/20/72', '4/12/87', '06/20/91', '5/12/2012', '3/15/83', '2/14/73', '5/24/88', '7/27/1986', '1-14-81', '7-29-75', '6/24/87', '8/14/94', '4/13/2002', '8/16/82', '2/15/1998', '7/15/91', '06/12/94', '9/17/84', '2/28/75']\n",
      "['11/22/75', '5/24/91', '6/13/92', '7/11/71', '12/26/86', '10/11/1987', '3/14/95', '12/01/73', '12/5/2010', '08/20/1982', '7/24/95', '8/06/83', '02/22/92', '6/28/87', '07/29/1994', '08/11/78', '10/29/91', '7/6/91', '1/21/87', '11/3/1985', '7/04/82... '09/19/81', '9/6/79', '12/5/87', '01/05/1999', '4/22/80', '10/04/98', '6/29/81', '8/04/78', '7/07/1974', '09/14/2000', '5/18/71', '8/09/1981', '6/05/93', '8/9/97', '12/8/82', '8/26/89', '10/13/95', '4/19/91', '04/08/2004', '9/20/76', '12/08/1990', '4/11/1974', '7/18/86', '3/31/91', '5/13/72', '011/14/83']\n",
      "['8/16/92', '10/05/97', '07/18/2002', '9/22/82', '2/24/74', '2/03/78', '2/11/2006', '8/22/83', '5/04/74', '7/20/2011', '6/17/95', '6/10/72', '10/16/82', '12/15/92', '12/8/97', '4/05/89', '12/04/87', '6/20/77', '4/27/2006', '07/17/92', '12/22/98', '10/02/96', '11/05/90', '5/04/77', '2/27/96', '24 Jan 2001', '10 Sep 2004', '26 May 1982', '28 June 2002', '06 May 1972', '25 Oct 1987', '14 Oct 1996', '30 Nov 2007', '28 June 1994', '14 Jan 1981', '10 Oct 1985', '11 February 1985', '10 Feb 1983', '05 Feb 1992', '21 Oct 2012', '14 Feb 1995', '30 May 2016', '22 Jan 1996', '14 Oct 1992', '06 Oct 2003', '18 Oct 1999', '11 Nov 2004', '30 May 2001', '02 Feb 1978', '09 Sep 1989']\n",
      "['12 March 1980 SOS-10 Total Score:\\n', '22 June 1990 Medical History:\\n', '28 Sep 2015 Primary Care Doctor:\\n', '13 Jan 1972 Primary Care Doctor:\\n', '06 Mar 1974 Primary Care Doctor:\\n', '10 Oct 1974 Primary Care Doctor:\\n', '26 May 1974 Primary Care Doctor:\\n', '10 Feb 1990\\n', '23 Aug 2000 Primary Care Doctor:\\n', '26 May 2001\\n', '21 Oct 2007 Schroder Hospital discharge summary', '19 Oct 2016 Communication with referring physician?: Done\\n', '05 Mar 1974\\n', '29 Jan 1994 Primary Care Doctor:\\n', '21 Oct 1978 Schroder Hospital discharge summary', '18 August 1975', '11 Nov 1996 CPT Code: 90792: With medical services\\n', '01 Oct 1979 Primary Care Doctor:\\n', '13 Oct 1986', '21 Oct 1995 Schroder Hospital discharge summary', '24 Jan 2011', '04 Oct 1972 Total time of visit (in minutes):\\n', '23 Aug 1993', '18 Oct 2006 Age:\\n', '04 Dec 1988', '21 Oct 1983', '26 May 2010 Education Education Level: College Grad\\n', '18 Jan 1990', '15 Jun 1985 @ 11 AMCommunication with referring physician?: Done\\n', '10 Dec 1982', '09 Dec 1988', '18 August 1995 Primary Care Doctor:\\n', '13 June 1974', '26 May 2008 Financial Stress: Yes\\n', '11 Nov 2002 SOS-10 Total Score:\\n', '17 Aug 1985 eval by Dr. Ngo.Social History Marital Status: Married\\n', '13 Oct 2016 Primary Care Doctor:\\n', '14 Jan 2008 Total time of visit (in minutes):\\n', '12 March 2004 CPT Code: 90801 - Psychiatric Diagnosis Interview\\n', '21 Oct 1977 Schroder Hospital discharge summary', '10 Aug 2000', '30 Nov 1972 SOS-10 Total Score:\\n', '06 May 1993 CPT Code: 90792: With medical services\\n', '18 Jan 1995', 'April 11, 1990 CPT Code: 90791: No medical services\\n', 'May 30, 2001', 'Feb 18, 1994', 'February 18, 1981', 'October. 11, 2013', 'Jan 24 1986']\n",
      "['July 26, 1978', 'December 23, 1999', 'May 15, 1989', 'September 06, 1995', 'Mar. 10, 1976', 'Jan 27, 1983', 'October 23 1990', 'August 12 2004', 'September 01, 2012', 'July 25, 1983', 'August 11, 1989', 'April 17, 1992', 'July 24, 1999', 'July 11, 1... 'May 15, 1998', 'October 14 1974', 'July 25, 1998', 'June 15, 1972', 'January 07, 1991', 'September. 15, 2011', 'September 1985', 'June 2011', 'Dec 14 1975', 'Oct 18, 1980', 'May 14, 1989', 'July 25, 1998', 'July, 1990', 'Jul 2003', 'Oct 2015', 'May 1995']\n",
      "136.2185664176941\n"
     ]
    }
   ],
   "source": [
    "delimiter_d=0\n",
    "delimiter_up=0\n",
    "dates=[]\n",
    "start_time = time.time()\n",
    "for i in range(5):\n",
    "    delimiter_d=delimiter_up\n",
    "    delimiter_up=50*(i+1)\n",
    "\n",
    "    text=list_[delimiter_d:delimiter_up]\n",
    "    prompt = f\"\"\"\n",
    "        Extract the dates of each sentence in the text delimited with triple backticks,  \\\n",
    "        if the day or month is not found, complete the date with day 01 and month 01, there are 50 dates\\\n",
    "        in the text, give me the results in a list.\n",
    "        ```{text}```\n",
    "        \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)\n",
    "    dates.append(response)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "#print(dates)\n",
    "print(execution_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472847c",
   "metadata": {},
   "source": [
    "As can be seen, the results show the extracted dates. However, something happened in batch 3, where the extracted results were not only the date, they include some text.\n",
    "The execution time of this code was 136 seconds, it is a elevated time for the extracted task in comparison of using regex, \n",
    "however, we just write 4 lines of a prompt insted of spending a considerable amount of time planning, writting and debugging \n",
    "a code using lists, pandas and regex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29f2fe",
   "metadata": {},
   "source": [
    "Now, we will iterate once again to extract the dates and change them to a specific format, this time we will use the \n",
    "list of the results of the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a30554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<03/25/93>, <6/18/85>, <7/8/71>, <9/27/75>, <2/6/96>, <7/06/79>, <5/18/78>, <10/24/89>, <3/7/86>, <4/10/71>, <5/11/85>, <4/09/75>, <8/01/98>, <1/26/72>, <5/24/1990>, <1/25/2011>, <4/12/82>, <10/13/1976>, <4/24/98>, <5/21/77>, <7/21/98>, <10/21/... <9/22/89>, <9/02/76>, <9/12/71>, <10/24/86>, <03/31/1985>, <7/20/72>, <4/12/87>, <06/20/91>, <5/12/2012>, <3/15/83>, <2/14/73>, <5/24/88>, <7/27/1986>, <1-14-81>, <7-29-75>, <6/24/87>, <8/14/94>, <4/13/2002>, <8/16/82>, <2/15/1998>, <7/15/91>, <06/12/94>, <9/17/84>, <2/28/75>\n",
      "<11/22/75>, <5/24/91>, <6/13/92>, <7/11/71>, <12/26/86>, <10/11/1987>, <3/14/95>, <12/01/73>, <12/5/2010>, <08/20/1982>, <7/24/95>, <8/06/83>, <02/22/92>, <6/28/87>, <07/29/1994>, <08/11/78>, <10/29/91>, <7/6/91>, <1/21/87>, <11/3/1985>, <7/04/82>, <... <09/19/81>, <9/6/79>, <12/5/87>, <01/05/1999>, <4/22/80>, <10/04/98>, <6/29/81>, <8/04/78>, <7/07/1974>, <09/14/2000>, <5/18/71>, <8/09/1981>, <6/05/93>, <8/9/97>, <12/8/82>, <8/26/89>, <10/13/95>, <4/19/91>, <04/08/2004>, <9/20/76>, <12/08/1990>, <4/11/1974>, <7/18/86>, <3/31/91>, <5/13/72>, <011/14/83>\n",
      "<8/16/92>, <10/05/97>, <07/18/2002>, <9/22/82>, <2/24/74>, <2/03/78>, <2/11/2006>, <8/22/83>, <5/04/74>, <7/20/2011>, <6/17/95>, <6/10/72>, <10/16/82>, <12/15/92>, <12/8/97>, <4/05/89>, <12/04/87>, <6/20/77>, <4/27/2006>, <07/17/92>, <12/22/98>, <10/02/96>, <11/05/90>, <5/04/77>, <2/27/96>, <24 Jan 2001>, <10 Sep 2004>, <26 May 1982>, <28 June 2002>, <06 May 1972>, <25 Oct 1987>, <14 Oct 1996>, <30 Nov 2007>, <28 June 1994>, <14 Jan 1981>, <10 Oct 1985>, <11 February 1985>, <10 Feb 1983>, <05 Feb 1992>, <21 Oct 2012>, <14 Feb 1995>, <30 May 2016>, <22 Jan 1996>, <14 Oct 1992>, <06 Oct 2003>, <18 Oct 1999>, <11 Nov 2004>, <30 May 2001>, <02 Feb 1978>, <09 Sep 1989>\n",
      "<12 March 1980>, <22 June 1990>, <28 Sep 2015>, <13 Jan 1972>, <06 Mar 1974>, <10 Oct 1974>, <26 May 1974>, <10 Feb 1990>, <23 Aug 2000>, <26 May 2001>, <21 Oct 2007>, <19 Oct 2016>, <05 Mar 1974>, <29 Jan 1994>, <21 Oct 1978>, <18 August 1975>, <11 Nov 1996>, <01 Oct 1979>, <13 Oct 1986>, <21 Oct 1995>, <24 Jan 2011>, <04 Oct 1972>, <23 Aug 1993>, <18 Oct 2006>, <04 Dec 1988>, <21 Oct 1983>, <26 May 2010>\n",
      "<18 Jan 1990>, <15 Jun 1985>, <10 Dec 1982>, <09 Dec 1988>, <18 August 1995>, <13 June 1974>, <26 May 2008>, <11 Nov 2002>, <17 Aug 1985>, <13 Oct 2016>, <14 Jan 2008>, <12 March 2004>, <21 Oct 1977>, <10 Aug 2000>, <30 Nov 1972>, <06 May 1993>, <18 Jan 1995>, <April 11, 1990>, <May 30, 2001>, <Feb 18, 1994>, <February 18, 1981>, <October. 11, 2013>, <Jan 24 1986>\n",
      "<July 26, 1978>, <December 23, 1999>, <May 15, 1989>, <September 06, 1995>, <Mar. 10, 1976>, <Jan 27, 1983>, <October 23 1990>, <August 12 2004>, <September 01, 2012>, <July 25, 1983>, <August 11, 1989>, <April 17, 1992>, <July 24, 1999>, <July 11, 1990>, <... <May 15, 1998>, <October 14 1974>, <July 25, 1998>, <June 15, 1972>, <January 07, 1991>, <September. 15, 2011>, <September 1985>, <June 2011>, <Dec 14 1975>, <Oct 18, 1980>, <May 14, 1989>, <July 25, 1998>, <July, 1990>, <Jul 2003>, <Oct 2015>, <May 1995>\n",
      "118.10968089103699\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "text=dates\n",
    "prompt = f\"\"\"\n",
    "        The text delimited with triple backticks contains different dates, change them to the same format delimited by <>\\ \n",
    "        and put them in a list\n",
    "        <month/day/year>\n",
    "        ```{text}```\n",
    "        \"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b231a6b1",
   "metadata": {},
   "source": [
    "As can be notice, the execution time is still considerably high, with 118 seconds,  but now we have a list of all the dates \n",
    "in a readable format, now we can make use of tools like timestamps to handle this items in a date format. \n",
    "We will only make use of a simple regular expression to extract all the dates of the previous response, as these results are \n",
    "only text. \n",
    "Now we can randomly print 10 different dates and see the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f968cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 25, 1998\n",
      "12 March 2004\n",
      "21 Oct 1977\n",
      "12/04/87\n",
      "18 August 1995\n",
      "8/14/94\n",
      "4/12/82\n",
      "4/13/2002\n",
      "29 Jan 1994\n",
      "18 August 1975\n"
     ]
    }
   ],
   "source": [
    "dates_extracted=[]\n",
    "date_pattern =r'<(.*?)>'\n",
    "dates_extracted= re.findall(date_pattern,response)\n",
    "random_indexes = [random.randint(0, 250 - 1) for _ in range(10)]\n",
    "for i in random_indexes:\n",
    "    print(dates_extracted[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
